{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Samno\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Samno\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Samno\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Samno\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Samno\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Samno\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\samno\\anaconda3\\lib\\site-packages (4.2.0.34)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\samno\\anaconda3\\lib\\site-packages (from opencv-python) (1.18.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "path=r\"D:\\Traffic sign recognition\"\n",
    "classes=43\n",
    "for i in range(classes):\n",
    "    pathes=os.path.join(path,'train',str(i))\n",
    "    images=os.listdir(pathes)\n",
    "    for a in images:\n",
    "        try:\n",
    "            img=cv2.imread(pathes+'\\\\'+a)\n",
    "            img=cv2.resize(img,(30,30))\n",
    "            img=np.array(img)\n",
    "            data.append(img)\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            print(\"Error processing image\")\n",
    "data=np.array(data)\n",
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39209, 30, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31367, 30, 30, 3) (31367,)\n"
     ]
    }
   ],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(data,labels,test_size=0.2)\n",
    "print(xtrain.shape,ytrain.shape)\n",
    "ytrain=to_categorical(ytrain)\n",
    "ytest=to_categorical(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(32,(5,5),activation='relu',input_shape=xtrain.shape[1:]))\n",
    "model.add(Conv2D(32,(5,5),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43,activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31367 samples, validate on 7842 samples\n",
      "Epoch 1/15\n",
      "31367/31367 [==============================] - 126s 4ms/sample - loss: 1.7821 - acc: 0.5647 - val_loss: 0.2488 - val_acc: 0.9445\n",
      "Epoch 2/15\n",
      "31367/31367 [==============================] - 126s 4ms/sample - loss: 0.4359 - acc: 0.8828 - val_loss: 0.1203 - val_acc: 0.9685\n",
      "Epoch 3/15\n",
      "31367/31367 [==============================] - 126s 4ms/sample - loss: 0.2768 - acc: 0.9254 - val_loss: 0.0924 - val_acc: 0.9796\n",
      "Epoch 4/15\n",
      "31367/31367 [==============================] - 126s 4ms/sample - loss: 0.2198 - acc: 0.9394 - val_loss: 0.0555 - val_acc: 0.9864\n",
      "Epoch 5/15\n",
      "31367/31367 [==============================] - 126s 4ms/sample - loss: 0.1865 - acc: 0.9493 - val_loss: 0.0571 - val_acc: 0.9871\n",
      "Epoch 6/15\n",
      "31367/31367 [==============================] - 126s 4ms/sample - loss: 0.1733 - acc: 0.9550 - val_loss: 0.0429 - val_acc: 0.9899\n",
      "Epoch 7/15\n",
      "31367/31367 [==============================] - 126s 4ms/sample - loss: 0.1470 - acc: 0.9608 - val_loss: 0.0573 - val_acc: 0.9857\n",
      "Epoch 8/15\n",
      "31367/31367 [==============================] - 126s 4ms/sample - loss: 0.1964 - acc: 0.9486 - val_loss: 0.0573 - val_acc: 0.9839\n",
      "Epoch 9/15\n",
      "31367/31367 [==============================] - 128s 4ms/sample - loss: 0.1589 - acc: 0.9587 - val_loss: 0.0748 - val_acc: 0.9814\n",
      "Epoch 10/15\n",
      "31367/31367 [==============================] - 127s 4ms/sample - loss: 0.1535 - acc: 0.9602 - val_loss: 0.0489 - val_acc: 0.9878\n",
      "Epoch 11/15\n",
      "31367/31367 [==============================] - 127s 4ms/sample - loss: 0.1389 - acc: 0.9640 - val_loss: 0.0546 - val_acc: 0.9853\n",
      "Epoch 12/15\n",
      "31367/31367 [==============================] - 136s 4ms/sample - loss: 0.1412 - acc: 0.9633 - val_loss: 0.0371 - val_acc: 0.9902\n",
      "Epoch 13/15\n",
      "31367/31367 [==============================] - 132s 4ms/sample - loss: 0.1379 - acc: 0.9663 - val_loss: 0.0273 - val_acc: 0.9926\n",
      "Epoch 14/15\n",
      "31367/31367 [==============================] - 127s 4ms/sample - loss: 0.1557 - acc: 0.9612 - val_loss: 0.0425 - val_acc: 0.9892\n",
      "Epoch 15/15\n",
      "31367/31367 [==============================] - 126s 4ms/sample - loss: 0.1217 - acc: 0.9687 - val_loss: 0.0472 - val_acc: 0.9885\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(xtrain,ytrain,epochs=15,batch_size=64,validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9588281868566905"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "testdata=pd.read_csv(r\"D:\\Traffic sign recognition\\Test.csv\")\n",
    "label=testdata[\"ClassId\"].values\n",
    "imgs=testdata[\"Path\"].values\n",
    "data=[]\n",
    "for imge in imgs:\n",
    "    image=cv2.imread(\"D:\\Traffic sign recognition\"+\"\\\\\" + imge)\n",
    "    image=cv2.resize(image,(30,30))\n",
    "    data.append(np.array(image))\n",
    "    \n",
    "xtest=np.array(data)\n",
    "pred=model.predict_classes(xtest)\n",
    "accuracy_score(pred,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('traffic_sign_classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
